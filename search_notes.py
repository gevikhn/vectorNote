import os
import sys
from pathlib import Path

# å¯¼å…¥é…ç½®æ–‡ä»¶
try:
    from config import (
        ROOT_DIR, COLLECTION_NAME, MODEL_NAME, 
        TOP_K, SCORE_THRESHOLD, FORCE_CPU,
        OFFLINE_MODE, LOCAL_MODEL_PATH, set_offline_mode
    )
except ImportError:
    print("é”™è¯¯: æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ config.py")
    sys.exit(1)

# å¤„ç†å‘½ä»¤è¡Œå‚æ•°
import argparse
parser = argparse.ArgumentParser(description="æœç´¢å‘é‡åŒ–çš„ç¬”è®°")
parser.add_argument("query", nargs="?", help="æœç´¢å…³é”®è¯")
parser.add_argument("--offline", action="store_true", help="å¯ç”¨ç¦»çº¿æ¨¡å¼ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜æ¨¡å‹")
parser.add_argument("--cpu", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨CPUè¿›è¡Œè®¡ç®—ï¼Œå³ä½¿æœ‰GPUå¯ç”¨")
args = parser.parse_args()

if args.offline:
    OFFLINE_MODE = True
    print("å·²å¯ç”¨ç¦»çº¿æ¨¡å¼")

if args.cpu:
    FORCE_CPU = True
    print("å·²å¯ç”¨å¼ºåˆ¶CPUæ¨¡å¼")

# è®¾ç½®ç¦»çº¿æ¨¡å¼ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥æ¨¡å—å‰è®¾ç½®ï¼‰
if OFFLINE_MODE:
    set_offline_mode(verbose=True)  # åœ¨ä¸»è„šæœ¬ä¸­ä¿ç•™æ—¥å¿—è¾“å‡º

# å¯¼å…¥å…¶ä»–æ¨¡å—
import torch
import hashlib
import uuid
import json
from datetime import datetime
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from rich.console import Console
from rich.markdown import Markdown
import re

console = Console()

# === æ£€æµ‹CUDAå¯ç”¨æ€§ ===
def check_cuda_availability():
    """æ£€æµ‹æ˜¯å¦æœ‰å¯ç”¨çš„CUDAè®¾å¤‡ï¼Œç‰¹åˆ«é’ˆå¯¹Windowsç¯å¢ƒä¼˜åŒ–"""
    # å¦‚æœå¼ºåˆ¶ä½¿ç”¨CPUï¼Œç›´æ¥è¿”å›
    if FORCE_CPU:
        console.print("[bold yellow]âš ï¸ å·²å¯ç”¨å¼ºåˆ¶CPUæ¨¡å¼ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œè®¡ç®—[/bold yellow]")
        return "cpu"
        
    try:
        # å°è¯•ç›´æ¥è·å–CUDAè®¾å¤‡ä¿¡æ¯
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            device_name = torch.cuda.get_device_name(0) if device_count > 0 else "æœªçŸ¥"
            console.print(f"[bold green]âœ… æ£€æµ‹åˆ° {device_count} ä¸ªCUDAè®¾å¤‡: {device_name}[/bold green]")
            console.print(f"[bold green]âœ… å°†ä½¿ç”¨GPUè¿›è¡ŒåŠ é€Ÿå¤„ç†[/bold green]")
            return "cuda"
        
        # å¦‚æœä¸Šé¢çš„æ£€æµ‹å¤±è´¥ï¼Œå°è¯•ç›´æ¥åˆ›å»ºCUDAå¼ é‡
        try:
            # å°è¯•åœ¨CUDAä¸Šåˆ›å»ºä¸€ä¸ªå°å¼ é‡
            test_tensor = torch.tensor([1.0], device="cuda")
            del test_tensor  # æ¸…ç†
            console.print(f"[bold green]âœ… é€šè¿‡æµ‹è¯•å¼ é‡æ£€æµ‹åˆ°CUDAè®¾å¤‡[/bold green]")
            console.print(f"[bold green]âœ… å°†ä½¿ç”¨GPUè¿›è¡ŒåŠ é€Ÿå¤„ç†[/bold green]")
            return "cuda"
        except RuntimeError as e:
            if "CUDA" in str(e):
                console.print(f"[bold yellow]âš ï¸ æ£€æµ‹åˆ°é”™è¯¯: {e}[/bold yellow]")
                console.print("[bold yellow]âš ï¸ ä½ çš„PyTorchæ²¡æœ‰CUDAæ”¯æŒ[/bold yellow]")
            pass
            
        # åœ¨Windowsä¸Šï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ£€æµ‹NVIDIAæ˜¾å¡
        nvidia_detected = False
        if os.name == 'nt':  # Windowsç³»ç»Ÿ
            try:
                # ä½¿ç”¨nvidia-smiå‘½ä»¤æ£€æµ‹æ˜¾å¡
                result = os.system('nvidia-smi >nul 2>&1')
                if result == 0:
                    console.print(f"[bold green]âœ… é€šè¿‡nvidia-smiæ£€æµ‹åˆ°NVIDIAæ˜¾å¡[/bold green]")
                    nvidia_detected = True
                    
                    # æ£€æŸ¥PyTorchæ˜¯å¦æ”¯æŒCUDA
                    if not torch.cuda.is_available():
                        console.print("[bold yellow]âš ï¸ æ£€æµ‹åˆ°NVIDIAæ˜¾å¡ï¼Œä½†å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒCUDA[/bold yellow]")
                        console.print("[bold yellow]âš ï¸ è¯·æ³¨æ„: ä½ ä½¿ç”¨çš„æ˜¯Python 3.13ï¼Œç›®å‰PyTorchå®˜æ–¹å°šæœªä¸ºæ­¤ç‰ˆæœ¬æä¾›CUDAæ”¯æŒ[/bold yellow]")
                        console.print("[bold yellow]âš ï¸ å»ºè®®æ–¹æ¡ˆ:[/bold yellow]")
                        console.print("[bold yellow]âš ï¸ 1. é™çº§åˆ°Python 3.10æˆ–3.11ï¼Œç„¶åå®‰è£…æ”¯æŒCUDAçš„PyTorch[/bold yellow]")
                        console.print("[bold yellow]âš ï¸    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121[/bold yellow]")
                        console.print("[bold yellow]âš ï¸ 2. æˆ–è€…ç»§ç»­ä½¿ç”¨CPUæ¨¡å¼ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰[/bold yellow]")
                        console.print("[bold yellow]âš ï¸ å°†ä½¿ç”¨CPUå¤„ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰[/bold yellow]")
                        return "cpu"
                    
                    # å¼ºåˆ¶è®¾ç½®CUDAå¯è§
                    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
                    # é‡æ–°åˆå§‹åŒ–CUDA
                    if torch.cuda.is_available():
                        device_name = torch.cuda.get_device_name(0)
                        console.print(f"[bold green]âœ… å·²å¯ç”¨CUDAè®¾å¤‡: {device_name}[/bold green]")
                        console.print(f"[bold green]âœ… å°†ä½¿ç”¨GPUè¿›è¡ŒåŠ é€Ÿå¤„ç†[/bold green]")
                        return "cuda"
            except Exception:
                pass
                
        # æ‰€æœ‰æ£€æµ‹æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨CPU
        if nvidia_detected:
            console.print("[bold yellow]âš ï¸ æ£€æµ‹åˆ°NVIDIAæ˜¾å¡ï¼Œä½†æ— æ³•å¯ç”¨CUDA[/bold yellow]")
            console.print("[bold yellow]âš ï¸ è¯·ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„CUDAç‰ˆæœ¬å’Œæ”¯æŒCUDAçš„PyTorch[/bold yellow]")
            console.print("[bold yellow]âš ï¸ è¿è¡Œ: pip uninstall torch torchvision torchaudio[/bold yellow]")
            console.print("[bold yellow]âš ï¸ ç„¶å: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121[/bold yellow]")
        else:
            console.print("[bold yellow]âš ï¸ æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUå¤„ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰[/bold yellow]")
            console.print("[bold yellow]âš ï¸ å¦‚æœä½ æœ‰NVIDIAæ˜¾å¡ï¼Œè¯·ç¡®ä¿å·²å®‰è£…æ­£ç¡®çš„CUDAå’ŒPyTorchç‰ˆæœ¬[/bold yellow]")
            console.print("[bold yellow]âš ï¸ æç¤º: å¯ä»¥å°è¯•è¿è¡Œ 'pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121'[/bold yellow]")
        
        return "cpu"
    except Exception as e:
        console.print(f"[bold yellow]âš ï¸ CUDAæ£€æµ‹å‡ºé”™: {e}[/bold yellow]")
        console.print("[bold yellow]âš ï¸ å°†ä½¿ç”¨CPUå¤„ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰[/bold yellow]")
        return "cpu"

# === åˆå§‹åŒ–ç»„ä»¶ ===
try:
    # ç¡®å®šè®¾å¤‡
    DEVICE = check_cuda_availability()
    
    print("æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
    
    # æ£€æŸ¥æœ¬åœ°æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœåœ¨ç¦»çº¿æ¨¡å¼ä¸‹ï¼‰
    if OFFLINE_MODE:
        print("æ­£åœ¨ç¦»çº¿æ¨¡å¼ä¸‹åŠ è½½æ¨¡å‹...")
        if os.path.exists(LOCAL_MODEL_PATH):
            print(f"æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_PATH}")
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
            model = SentenceTransformer(LOCAL_MODEL_PATH, device=DEVICE)
        else:
            console.print(f"[bold red]é”™è¯¯: æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_PATH}[/bold red]")
            console.print("[bold yellow]è¯·å…ˆåœ¨è”ç½‘çŠ¶æ€ä¸‹è¿è¡Œä¸€æ¬¡ç¨‹åºä¸‹è½½æ¨¡å‹ï¼Œæˆ–è€…æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•[/bold yellow]")
            sys.exit(1)
    else:
        # æ­£å¸¸æ¨¡å¼ä¸‹åŠ è½½åœ¨çº¿æ¨¡å‹
        model = SentenceTransformer(MODEL_NAME, device=DEVICE)
    
    print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    print("æ­£åœ¨è¿æ¥å‘é‡æ•°æ®åº“...")
    client = QdrantClient(path="./qdrant_data")
    
    # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    if not client.collection_exists(COLLECTION_NAME):
        console.print(f"[bold red]é”™è¯¯: é›†åˆ {COLLECTION_NAME} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ scan_and_embed_notes.py[/bold red]")
        sys.exit(1)
    print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
except Exception as e:
    console.print(f"[bold red]åˆå§‹åŒ–å¤±è´¥: {e}[/bold red]")
    sys.exit(1)

def enhance_query(query: str):
    """
    å¢å¼ºæŸ¥è¯¢æ–‡æœ¬ï¼Œæé«˜æ£€ç´¢æ•ˆæœ
    """
    # 1. å»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
    query = re.sub(r'\s+', ' ', query).strip()
    
    # 2. æ·»åŠ æŸ¥è¯¢å‰ç¼€ï¼Œæé«˜æ£€ç´¢è´¨é‡ï¼ˆBGEæ¨¡å‹ç‰¹æ€§ï¼‰
    enhanced_query = f"æŸ¥è¯¢ï¼š{query}"
    
    return enhanced_query

def search_notes(query: str, model=None, client=None):
    """æœç´¢ç¬”è®°"""
    # å¦‚æœæ²¡æœ‰ä¼ å…¥æ¨¡å‹å’Œå®¢æˆ·ç«¯ï¼Œåˆ™ä½¿ç”¨å…¨å±€å˜é‡
    if model is None or client is None:
        # è¿™é‡Œä¸å†é‡æ–°åŠ è½½æ¨¡å‹å’Œå®¢æˆ·ç«¯ï¼Œè€Œæ˜¯ä½¿ç”¨å…¨å±€å·²åŠ è½½çš„
        console.print("[bold yellow]è­¦å‘Š: æœªä¼ å…¥æ¨¡å‹æˆ–å®¢æˆ·ç«¯ï¼Œä½¿ç”¨å…¨å±€å˜é‡[/bold yellow]")
        # ç¡®ä¿å…¨å±€å˜é‡å·²å®šä¹‰
        if 'model' not in globals() or 'client' not in globals():
            console.print("[bold red]é”™è¯¯: å…¨å±€æ¨¡å‹æˆ–å®¢æˆ·ç«¯æœªåˆå§‹åŒ–[/bold red]")
            sys.exit(1)
        model = globals()['model']
        client = globals()['client']
    
    # å¢å¼ºæŸ¥è¯¢
    enhanced_query = enhance_query(query)
    
    # å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    query_vector = model.encode(enhanced_query)
    
    # åœ¨ Qdrant ä¸­æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£
    search_result = client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vector,
        limit=TOP_K * 3,  # è·å–æ›´å¤šç»“æœï¼Œåé¢ä¼šè¿‡æ»¤å’Œé‡æ’åº
        score_threshold=SCORE_THRESHOLD  # é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¢åŠ å¬å›ç‡
    ).points
    
    # æ˜¾ç¤ºæœç´¢ç»“æœ
    console.print(f"\nğŸ” æœç´¢ï¼š[bold blue]{query}[/bold blue]\n")
    
    # æ–‡ä»¶åç²¾ç¡®åŒ¹é…æœç´¢ï¼ˆä¼˜å…ˆæ˜¾ç¤ºï¼‰
    file_matches = []
    query_terms = query.lower().split()
    
    # æ ¹æ®æ–‡ä»¶è·¯å¾„å’Œæ–‡ä»¶åè¿›è¡ŒåŒ¹é…
    for result in search_result:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶åå‘é‡ç‚¹
        is_filename_only = result.payload.get("is_filename_only", False)
        
        # è·å–æ–‡ä»¶å
        filename = result.payload.get("filename", "")
        if not filename:
            source_path = Path(result.payload["source"])
            filename = source_path.name
            
        filename_lower = filename.lower()
        
        # æ–‡ä»¶åå‘é‡ç‚¹ä¼˜å…ˆçº§æ›´é«˜
        if is_filename_only and all(term in filename_lower for term in query_terms):
            file_matches.insert(0, result)  # æ’å…¥åˆ°æœ€å‰é¢
        # æ™®é€šå‘é‡ç‚¹ä½†æ–‡ä»¶ååŒ¹é…
        elif all(term in filename_lower for term in query_terms):
            file_matches.append(result)
    
    # ç›´æ¥åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æœç´¢åŒ¹é…çš„æ–‡ä»¶ï¼ˆä»¥é˜²å‘é‡æ•°æ®åº“ä¸­æ²¡æœ‰ç´¢å¼•åˆ°ï¼‰
    if not file_matches and len(search_result) < 2:  # åªæœ‰åœ¨å‘é‡æœç´¢ç»“æœå¾ˆå°‘æ—¶æ‰æ‰§è¡Œ
        console.print("[dim]æ­£åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æœç´¢åŒ¹é…æ–‡ä»¶...[/dim]")
        for root, dirs, files in os.walk(ROOT_DIR):
            for file in files:
                if file.lower().endswith('.md') and all(term in file.lower() for term in query_terms):
                    full_path = os.path.join(root, file)
                    try:
                        # è¯»å–æ–‡ä»¶å†…å®¹
                        with open(full_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # ç›´æ¥æ˜¾ç¤ºæ–‡ä»¶ç³»ç»Ÿæœç´¢ç»“æœ
                        console.print(f"\n[bold yellow]æ–‡ä»¶ç³»ç»ŸåŒ¹é…[/bold yellow]")
                        console.print(f"[bold cyan]æ–‡ä»¶: {file}[/bold cyan]")
                        
                        # æå–æ–‡ä»¶çš„ä¸»è¦å†…å®¹
                        lines = content.split('\n')
                        # å»é™¤ç©ºè¡Œ
                        lines = [line for line in lines if line.strip()]
                        
                        # æå–å‰10è¡Œéç©ºå†…å®¹ä½œä¸ºé¢„è§ˆ
                        preview_lines = lines[:10]
                        preview = '\n'.join(preview_lines)
                        if len(lines) > 10:
                            preview += "\n..."
                        
                        # æ˜¾ç¤ºé¢„è§ˆå†…å®¹
                        console.print("\n[bold]æ–‡ä»¶å†…å®¹é¢„è§ˆ:[/bold]")
                        for line in preview_lines:
                            console.print(line)
                            
                        console.print(f"\n[dim]æ¥æº: {full_path}[/dim]\n")
                        console.print("â”€" * 80)
                        
                    except Exception as e:
                        console.print(f"[dim]è¯»å–æ–‡ä»¶ {full_path} æ—¶å‡ºé”™: {e}[/dim]")
    
    # é‡æ’åºç»“æœï¼šç»“åˆç›¸ä¼¼åº¦åˆ†æ•°å’Œå…³é”®è¯åŒ¹é…åº¦
    def rerank_score(result):
        base_score = result.score
        text = result.payload["text"].lower()
        
        # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
        keyword_bonus = 0
        for term in query_terms:
            if term in text:
                # æ ¹æ®å…³é”®è¯å‡ºç°çš„ä½ç½®ç»™äºˆä¸åŒæƒé‡
                # æ ‡é¢˜ä¸­å‡ºç°çš„å…³é”®è¯æƒé‡æ›´é«˜
                if term in text.split('\n')[0]:
                    keyword_bonus += 0.1
                else:
                    keyword_bonus += 0.05
        
        # æ–‡ä»¶ååŒ¹é…åŠ åˆ†
        filename_bonus = 0
        filename = result.payload.get("filename", "").lower()
        if any(term in filename for term in query_terms):
            filename_bonus = 0.15
        
        # æ˜¯å¦ä¸ºæ–‡ä»¶åå‘é‡ç‚¹
        is_filename_only = result.payload.get("is_filename_only", False)
        filename_only_bonus = 0.2 if is_filename_only and any(term in filename for term in query_terms) else 0
        
        # æœ€ç»ˆåˆ†æ•°
        final_score = base_score + keyword_bonus + filename_bonus + filename_only_bonus
        return final_score
    
    # åˆå¹¶ç»“æœï¼Œåªä½¿ç”¨å‘é‡æœç´¢ç»“æœ
    combined_results = file_matches + [r for r in search_result if r not in file_matches]
    
    # æ ¹æ®é‡æ’åºåˆ†æ•°æ’åº
    combined_results.sort(key=rerank_score, reverse=True)
    
    # å»é‡å¹¶é™åˆ¶ç»“æœæ•°é‡
    unique_results = []
    unique_paths = set()
    
    for result in combined_results:
        source = result.payload["source"]
        if source not in unique_paths and len(unique_results) < TOP_K:
            unique_paths.add(source)
            unique_results.append(result)
    
    # æ˜¾ç¤ºç»“æœ
    if not unique_results:
        console.print("[yellow]æœªæ‰¾åˆ°ç›¸å…³ç»“æœ[/yellow]")
        return
    
    for i, result in enumerate(unique_results, 1):
        score = result.score
        text = result.payload["text"]
        source = result.payload["source"]
        
        # æå–æ–‡ä»¶åä½œä¸ºé¢å¤–æ˜¾ç¤º
        filename = Path(source).name
        
        # æ˜¾ç¤ºç»“æœæ ‡é¢˜
        console.print(f"\n[bold green]ç»“æœ {i} (ç›¸ä¼¼åº¦: {score:.2f})[/bold green]")
        console.print(f"[bold cyan]æ–‡ä»¶: {filename}[/bold cyan]")
        console.print("\n")
        
        # å°è¯•è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
        content_to_display = ""
        try:
            if os.path.exists(source):
                with open(source, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æå–æ–‡ä»¶çš„å‰30è¡Œéç©ºå†…å®¹
                lines = content.split('\n')
                non_empty_lines = []
                for line in lines:
                    if line.strip():
                        non_empty_lines.append(line)
                    if len(non_empty_lines) >= 30:
                        break
                
                if non_empty_lines:
                    content_to_display = '\n'.join(non_empty_lines)
                    if len(lines) > 30:
                        content_to_display += "\n..."
                else:
                    content_to_display = text
            else:
                content_to_display = text
        except Exception:
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æœ¬
            content_to_display = text
        
        # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if not isinstance(content_to_display, str):
            try:
                content_to_display = str(content_to_display)
            except Exception:
                content_to_display = "é”™è¯¯ï¼šæ— æ³•æ˜¾ç¤ºå†…å®¹ï¼Œå†…å®¹æ ¼å¼ä¸æ­£ç¡®"
        
        console.print(Markdown(content_to_display))
        
        console.print(f"\n[dim]æ¥æº: {source}[/dim]")
        console.print("â”€" * 80)

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨å…¨å±€å˜é‡
    global model, client
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2 and not args.query:
        console.print("[bold red]è¯·æä¾›æœç´¢å…³é”®è¯[/bold red]")
        console.print("ç”¨æ³•: python search_notes.py \"æœç´¢å…³é”®è¯\"")
        sys.exit(1)
    
    # è·å–æŸ¥è¯¢æ–‡æœ¬
    query = args.query if args.query else " ".join(sys.argv[1:])
    
    # ä½¿ç”¨å…¨å±€å·²åŠ è½½çš„æ¨¡å‹å’Œå®¢æˆ·ç«¯è¿›è¡Œæœç´¢
    search_notes(query, model, client)

if __name__ == "__main__":
    main()